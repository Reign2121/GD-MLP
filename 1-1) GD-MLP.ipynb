{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609d3adf-df68-4441-b606-9a943c1016fc",
   "metadata": {},
   "source": [
    "# GD-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85832b1-9f31-41e4-b934-cc260e5b3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb.init(project=\"TSF\", name=\"GD-MLP\")\n",
    "wandb_logger = WandbLogger(project=\"TSF\", name=\"GD-MLP\")\n",
    "\n",
    "parser = ArgumentParser(description=\"GD-MLP\")\n",
    "\n",
    "# data loader\n",
    "parser.add_argument('--data', type=str, default='Exchange', help='dataset type')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=336, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=336, help='start token length')\n",
    "parser.add_argument('--pred_len', type=int, default=336, help='prediction sequence length')\n",
    "\n",
    "# GD-MLP\n",
    "parser.add_argument('--num_features', type=int, default=1)\n",
    "parser.add_argument('--hidden_units', type=int, default=512)\n",
    "\n",
    "# DLinear\n",
    "# parser.add_argument('--individual', action='store_true', default=False, help='DLinear: a linear layer for each variate(channel) individually')\n",
    "# parser.add_argument('--enc_in', type=int, default=1, help='encoder input size') # DLinear with --individual, use this hyperparameter as the number of channels\n",
    "\n",
    "## train\n",
    "parser.add_argument('--loss', default=\"mse\", type=str)\n",
    "parser.add_argument('--optimizer', default=\"adam\", type=str)\n",
    "parser.add_argument('--learning_rate', default=0.0001, type=float)\n",
    "parser.add_argument('--scheduler', default=\"none\", type=str)\n",
    "parser.add_argument('--batch_size', default=512, type=int)\n",
    "parser.add_argument('--epochs', default=30, type=int)\n",
    "# parser.add_argument('--validation_size', default=0.2, type=float)\n",
    "parser.add_argument('--seed', default=826, type=int)\n",
    "parser.add_argument('--mixed_precision', default=16, type=int)\n",
    "parser.add_argument('--device', nargs='+', default=[0], type=int)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "wandb.config.update(args)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "BATCH_SIZE = args.batch_size\n",
    "EPOCHS = args.epochs\n",
    "# VALIDATION_SIZE = args.validation_size\n",
    "SEED = args.seed\n",
    "\n",
    "def set_seeds(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(SEED)\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "submission_id = f\"{parser.description}_{args.data}_pl{args.pred_len}\"\n",
    "submission_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85903024-c1e6-4dad-87b1-970ef63a1c59",
   "metadata": {},
   "source": [
    "## Input/Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0309fd3-cd74-40bf-a6ea-83e3004abd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.data == \"ETTh1\":\n",
    "    df = pd.read_csv(\"dataset/ETT-small/ETTh1.csv\")\n",
    "if args.data == \"ETTh2\":\n",
    "    df = pd.read_csv(\"dataset/ETT-small/ETTh2.csv\")\n",
    "if args.data == \"ETTm1\":\n",
    "    df = pd.read_csv(\"dataset/ETT-small/ETTm1.csv\")\n",
    "if args.data == \"ETTm2\":\n",
    "    df = pd.read_csv(\"dataset/ETT-small/ETTm2.csv\")\n",
    "if args.data == \"Exchange\":\n",
    "    df = pd.read_csv(\"dataset/exchange_rate/exchange_rate.csv\")\n",
    "\n",
    "# data = data.drop(\"date\", axis=1)\n",
    "df = df[[\"OT\"]]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc42d4-96ff-4851-a4f2-e726bdad980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Seq_Dataset(Dataset):\n",
    "    def __init__(self, data, input_len,label_len, pred_len, target):\n",
    "        self.data = data\n",
    "        self.target = data[target].values #numpy\n",
    "        self.data = data.values\n",
    "        self.input_len = input_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.input_len - self.label_len + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # feature and target\n",
    "        feature = self.data[idx:idx+self.input_len]\n",
    "        target = self.target[idx+(self.input_len-1):(idx+self.input_len + self.label_len-1)]\n",
    "\n",
    "        # convert to tensor and reshape\n",
    "        feature = torch.tensor(feature, dtype=torch.float32)\n",
    "        target = torch.tensor(target, dtype=torch.float32).unsqueeze(1) #unsqueeze, 차원확장 (feature 차원 추가)\n",
    "        \n",
    "        return feature, target\n",
    "      \n",
    "data = Custom_Seq_Dataset(data=df, input_len=args.seq_len, label_len=args.label_len, pred_len=args.pred_len, target='OT') #Hyperparameter\n",
    "    \n",
    "\n",
    "#분할    \n",
    "train_size = int(0.7 * len(data))  #분할했을 때 수 반환해서 미리 체크\n",
    "val_size = int(0.1 * len(data))    \n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_indices = list(range(train_size)) #데이터를 시간의 순서대로 분할하기 위해 순서대로 인덱스 생성\n",
    "val_indices = list(range(train_size, train_size + val_size))\n",
    "test_indices = list(range(train_size + val_size, len(data)))\n",
    "\n",
    "from torch.utils.data import Subset #하위 데이터로 나누기.\n",
    "train_set = Subset(data, train_indices) #(데이터 셋, 인덱스).\n",
    "val_set = Subset(data, val_indices)\n",
    "test_set = Subset(data, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68c38e",
   "metadata": {},
   "source": [
    "## Input/DataLoader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac9564-17bb-4bba-83ad-e3f0e8c06e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "val_loader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "\n",
    "#check it\n",
    "print(train_labels.shape)\n",
    "print(train_features.shape)\n",
    "print(test_labels.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f0b66-817d-49ff-9163-a975fb0f239d",
   "metadata": {},
   "source": [
    "## Model/GD-MLP.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58234b18-aaf7-424d-9371-5fee4e479d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ([batch_size, seq_len, features)]\n",
    "# ex) batch_size = 8, seq_len = 336, features = 1, hidden_uits = 512\n",
    "# input.shape = torch.Size([8, 336, 1)]\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    * decomposition Source from autoformer, Dlinear\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1) # -> torch.Size([8, 360, 1])\n",
    "        x = self.avg(x.permute(0, 2, 1)) # -> torch.Size([8, 1, 336])\n",
    "        x = x.permute(0, 2, 1) # -> torch.Size([8, 336, 1])\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    * decomposition Source from autoformer, Dlinear\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        trend = self.moving_avg(x)\n",
    "        res = x - trend\n",
    "        return res, trend #torch.Size([8, 336, 1])\n",
    "\n",
    "\n",
    "class gated_mlp (nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    MLP block(gated_mlp)\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len, num_features, pred_len, hidden_units):\n",
    "        super(gated_mlp, self).__init__()\n",
    "        self.seq_len = seq_len #인풋 길이\n",
    "        self.num_features = num_features #피처 수\n",
    "        self.pred_len = pred_len # 예측 길이\n",
    "        self.hidden_units = hidden_units #노드 수\n",
    "        kernel_size = 25 #same as Autoformer, Dlinear\n",
    "        self.decomposition = series_decomp(kernel_size)\n",
    "        \n",
    "        # self.input_layer = nn.Linear(self.num_features, 1)\n",
    "\n",
    "\n",
    "        reduction = 4\n",
    "        \n",
    "        self.input_gate1 = nn.Sequential(\n",
    "            nn.Linear(self.seq_len, self.seq_len//reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.seq_len//reduction, self.seq_len, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        ) #Input_gate\n",
    "        \n",
    "        self.input_gate2 = nn.Sequential(\n",
    "            nn.Linear(self.seq_len, self.seq_len//reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.seq_len//reduction, self.seq_len, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        ) #Input_gate\n",
    "\n",
    "\n",
    "        # self.trend_mlp = nn.Sequential(\n",
    "        #     nn.Linear(self.seq_len, self.hidden_units),\n",
    "        #     nn.Linear(self.hidden_units, self.hidden_units)\n",
    "        # ) # MLP for Trend\n",
    "\n",
    "\n",
    "        # self.residual_mlp = nn.Sequential(\n",
    "        #     nn.Linear(self.seq_len, self.hidden_units),\n",
    "        #     nn.Linear(self.hidden_units, self.hidden_units)\n",
    "        # ) # MLP for Residual\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        residual_train,trend_train = self.decomposition(x) # torch.Size([8, 336, 1])\n",
    "\n",
    "        #input_layer #not necessary\n",
    "        # trend_train = self.input_layer(trend_train) #-> torch.Size([8, 336, 1])\n",
    "        # residual_train = self.input_layer(residual_train)\n",
    "\n",
    "        residual_train, trend_train = residual_train.permute(0,2,1), trend_train.permute(0,2,1) #-> torch.Size([8, 1, 336])\n",
    "        \n",
    "        # input_gate\n",
    "        # i_gate_t = self.input_gate1(trend_train) #-> torch.Size([8, 1, 336])\n",
    "        # trend_train = trend_train * i_gate_t #-> torch.Size([8, 1, 336])\n",
    "\n",
    "        i_gate_r = self.input_gate2(residual_train) #-> torch.Size([8, 1, 336])\n",
    "        residual_train = residual_train * i_gate_r #-> torch.Size([8, 1, 336])\n",
    "\n",
    "        # trend MLP (gated)\n",
    "        # trend_mlp = self.trend_mlp(trend_train) #MLP 통과 #-> torch.Size([8, 1, 512])\n",
    "\n",
    "        # # residual MLP(gated)\n",
    "        # residual_mlp = self.residual_mlp(residual_train) #MLP 통과 #-> torch.Size([8, 1, 512])\n",
    "      \n",
    "\n",
    "        # return trend_mlp, residual_mlp #torch.Size([8, 1, 512])\n",
    "        return trend_train, residual_train #torch.Size([8, 1, 512])\n",
    "\n",
    "\n",
    "\n",
    "class gated_sum(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Composing block with gate\n",
    "    \"\"\"\n",
    "     \n",
    "    def __init__(self, seq_len, num_features, pred_len, hidden_units):\n",
    "        super(gated_sum, self).__init__()\n",
    "        self.seq_len = seq_len #인풋 길이\n",
    "        self.num_features = num_features #same as gated mlp\n",
    "        self.pred_len = pred_len\n",
    "        self.hidden_units = hidden_units\n",
    "        kernel_size = 25\n",
    "        self.decomposition = series_decomp(kernel_size)\n",
    "        self.gated_mlp = gated_mlp(seq_len, num_features, pred_len, hidden_units) \n",
    "        \n",
    "        self.output_layer1 = nn.Linear(self.seq_len, self.pred_len) #pred_len으로 선형변환하기 위한 output_layer\n",
    "        self.output_layer2 = nn.Linear(self.seq_len, self.pred_len) \n",
    "        \n",
    "        #Output gate\n",
    "        self.output_gate = nn.Sequential(\n",
    "            nn.Linear(self.pred_len, 1), #가중합 하기 위한 gate  \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # gated_mlp\n",
    "        trend_mlp, residual_mlp = self.gated_mlp(x)  #gated_mlp 블록을 통과 #->torch.Size([8, 1, 512])\n",
    "\n",
    "        # output layer\n",
    "        output_trend = self.output_layer1(trend_mlp)  #output_layer 통과 #->torch.Size([8, 1, 96])\n",
    "        output_residual = self.output_layer2(residual_mlp) #output_layer 통과 #->torch.Size([8, 1, 96])\n",
    "        \n",
    "        # combine trend and residual MLPs with weighted sum\n",
    "        trend_weight = self.output_gate(output_trend) # gate 통과 #->torch.Size([8, 1, 1])\n",
    "        residual_weight = (1-trend_weight)\n",
    "\n",
    "        #trend_weight,residual_weight = trend_weight.permute(0,2,1), residual_weight.permute(0,2,1)\n",
    "\n",
    "        weighted_sum = (output_trend * trend_weight) + (output_residual * residual_weight) # Weighted sum == Final Output #->torch.Size([8, 1, 96])\n",
    "\n",
    "        # weighted_sum = output_trend + output_residual\n",
    "        \n",
    "        return weighted_sum.permute(0,2,1) #Final Output #->torch.Size([8, 96, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685755e-a1b0-4bf5-96bd-747bc116cfce",
   "metadata": {},
   "source": [
    "## DLinear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2a824-240c-412c-85cb-bf964020ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class moving_avg(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Moving average block to highlight the trend of time series\n",
    "#     \"\"\"\n",
    "#     def __init__(self, kernel_size, stride):\n",
    "#         super(moving_avg, self).__init__()\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # padding on the both ends of time series\n",
    "#         front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "#         end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "#         x = torch.cat([front, x, end], dim=1)\n",
    "#         x = self.avg(x.permute(0, 2, 1))\n",
    "#         x = x.permute(0, 2, 1)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class series_decomp(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Series decomposition block\n",
    "#     \"\"\"\n",
    "#     def __init__(self, kernel_size):\n",
    "#         super(series_decomp, self).__init__()\n",
    "#         self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         moving_mean = self.moving_avg(x)\n",
    "#         res = x - moving_mean\n",
    "#         return res, moving_mean\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Decomposition-Linear\n",
    "#     \"\"\"\n",
    "#     def __init__(self, configs):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.seq_len = configs.seq_len\n",
    "#         self.pred_len = configs.pred_len\n",
    "\n",
    "#         # Decompsition Kernel Size\n",
    "#         kernel_size = 25\n",
    "#         self.decompsition = series_decomp(kernel_size)\n",
    "#         self.individual = configs.individual\n",
    "#         self.channels = configs.enc_in\n",
    "\n",
    "#         if self.individual:\n",
    "#             self.Linear_Seasonal = nn.ModuleList()\n",
    "#             self.Linear_Trend = nn.ModuleList()\n",
    "            \n",
    "#             for i in range(self.channels):\n",
    "#                 self.Linear_Seasonal.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "#                 self.Linear_Trend.append(nn.Linear(self.seq_len,self.pred_len))\n",
    "\n",
    "#                 # Use this two lines if you want to visualize the weights\n",
    "#                 # self.Linear_Seasonal[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "#                 # self.Linear_Trend[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "#         else:\n",
    "#             self.Linear_Seasonal = nn.Linear(self.seq_len,self.pred_len)\n",
    "#             self.Linear_Trend = nn.Linear(self.seq_len,self.pred_len)\n",
    "            \n",
    "#             # Use this two lines if you want to visualize the weights\n",
    "#             # self.Linear_Seasonal.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "#             # self.Linear_Trend.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: [Batch, Input length, Channel]\n",
    "#         seasonal_init, trend_init = self.decompsition(x)\n",
    "#         seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
    "#         if self.individual:\n",
    "#             seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.pred_len],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
    "#             trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.pred_len],dtype=trend_init.dtype).to(trend_init.device)\n",
    "#             for i in range(self.channels):\n",
    "#                 seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
    "#                 trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
    "#         else:\n",
    "#             seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
    "#             trend_output = self.Linear_Trend(trend_init)\n",
    "\n",
    "#         x = seasonal_output + trend_output\n",
    "#         return x.permute(0,2,1) # to [Batch, Output length, Channel]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fba1e1-43c6-4274-9c82-cf910217dce7",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04cd969-59d8-44a6-afe3-8f79640d4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDMLP(pl.LightningModule):\n",
    "    def __init__(self, backbone, args):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def step(self, batch):\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_hat = self.forward(x)\n",
    "        loss = nn.MSELoss()(y_hat, y)\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def metric(self, pred, true):\n",
    "        mae = np.mean(np.abs(pred - true))\n",
    "        mse = np.mean((pred - true) ** 2)\n",
    "        return mae, mse\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        pred = y_hat.detach().cpu().numpy()\n",
    "        true = y.detach().cpu().numpy()\n",
    "        mae, mse = self.metric(pred, true)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_mae\", mae, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_mse\", mse, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        pred = y_hat.detach().cpu().numpy()\n",
    "        true = y.detach().cpu().numpy()\n",
    "        mae, mse = self.metric(pred, true)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_mae\", mae, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_mse\", mse, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        pred = y_hat.detach().cpu().numpy()\n",
    "        true = y.detach().cpu().numpy()\n",
    "        mae, mse = self.metric(pred, true)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_mae\", mae, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_mse\", mse, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x = batch[0]\n",
    "        y_hat = self.forward(x)\n",
    "        return y_hat\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if args.optimizer == \"sgd\":\n",
    "            optimizer = torch.optim.SGD(self.parameters(), lr=args.learning_rate, momentum=0.9)\n",
    "        if args.optimizer == \"adam\":\n",
    "            optimizer = torch.optim.Adam(self.parameters(), lr=args.learning_rate)\n",
    "        if args.optimizer == \"adamw\":\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), lr=args.learning_rate)\n",
    "        \n",
    "        if args.scheduler == \"none\":\n",
    "            return optimizer\n",
    "        if args.scheduler == \"step\":\n",
    "            scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "                optimizer=optimizer,\n",
    "                step_size=2,\n",
    "                gamma=0.9,\n",
    "            )\n",
    "            return [optimizer], [scheduler]\n",
    "        if args.scheduler == \"cosine\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer=optimizer,\n",
    "                T_max=EPOCHS,\n",
    "                eta_min=1e-5,\n",
    "            )\n",
    "        if args.scheduler == \"onecyclelr\":\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer=optimizer,\n",
    "                max_lr=args.learning_rate,\n",
    "                epochs=EPOCHS,\n",
    "                steps_per_epoch=int(len(train_index) / BATCH_SIZE),\n",
    "                pct_start=0.1,\n",
    "            )\n",
    "            return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f79f7d",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d7ca0-899e-4515-a43e-890549f8f3c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = GDMLP(gated_sum(args.seq_len, args.num_features, args.pred_len, args.hidden_units), args)\n",
    "\n",
    "callbacks = [\n",
    "    pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=\"saved/\", filename=f\"{submission_id}\",\n",
    "        monitor=\"val_loss\", mode=\"min\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS, accelerator=\"auto\", callbacks=callbacks,\n",
    "    precision=args.mixed_precision, logger=wandb_logger,\n",
    "    devices=args.device\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "ckpt = torch.load(f\"saved/{submission_id}.ckpt\", map_location=torch.device(device))\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "## test.py\n",
    "\n",
    "eval_dict = trainer.validate(model, dataloaders=val_loader)[0]\n",
    "wandb.log({'eval_loss': eval_dict[\"val_loss\"]})\n",
    "wandb.log({'eval_mae': eval_dict[\"val_mae\"]})\n",
    "wandb.log({'eval_mse': eval_dict[\"val_mse\"]})\n",
    "\n",
    "y_preds = trainer.predict(model, dataloaders=test_loader)\n",
    "pred = np.vstack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5c540c-800c-4881-8c20-435cd725cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in test_set:\n",
    "    true.append(i[1])\n",
    "\n",
    "true = np.stack(true)\n",
    "\n",
    "mae = np.mean(np.abs(pred - true))\n",
    "mse = np.mean((pred - true) ** 2)\n",
    "\n",
    "print(f\"test_mae: {mae}\")\n",
    "print(f\"test_mse: {mse}\")\n",
    "\n",
    "wandb.log({'test_mae': mae})\n",
    "wandb.log({'test_mse': mse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3e4b7-e2a5-4c6d-9716-f7035bbf85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2034d62-1efe-4686-b8f3-aa9b4c8274a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
